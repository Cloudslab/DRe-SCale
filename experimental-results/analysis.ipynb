{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow tbparse\n",
    "# %pip install tbparse\n",
    "from datetime import datetime\n",
    "import time as time\n",
    "import math\n",
    "from statistics import mean\n",
    "import json as json\n",
    "import numpy as np\n",
    "from tbparse import SummaryReader\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-PPO, PPO, DRQN Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "log_dir = './${PPO_LOG_DIR}'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_ppo = reader.scalars\n",
    "\n",
    "\n",
    "log_dir = './${RPPO_LOG_DIR}'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_rppo = reader.scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data ------- environment scalars\n",
    "log_dir = './${PPO_LOG_DIR}/scalars'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_ppo_ = reader.tensors\n",
    "\n",
    "\n",
    "log_dir = './${RPPO_LOG_DIR}/scalars'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_rppo_ = reader.tensors\n",
    "\n",
    "log_dir = './${DQN_LOG_DIR}'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_dqn_ = reader.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents trained for 5 minutes for motre than 500 episodes\n",
    "ppox = df_ppo_['step'].to_numpy()[:533]\n",
    "ppoy = [i for i in df_ppo_[df_ppo_['episode'] <= 533]['mean_reward'] if not math.isnan(i)]\n",
    "\n",
    "rppox = df_rppo_['step'].to_numpy()[:533]\n",
    "rppoy = [i for i in df_rppo_[df_rppo_['episode'] <= 533]['mean_reward'] if not math.isnan(i)][:533]\n",
    "\n",
    "dqn_x = [i for i in range(533)]\n",
    "dqn_y = [i for i in df_dqn_[df_dqn_['episode'] <= 533]['mean_reward'] if not math.isnan(i)][:533]\n",
    "pyplot.plot(ppox, ppoy, color='red')\n",
    "pyplot.plot(rppox, rppoy, color='green')\n",
    "pyplot.plot(dqn_x, dqn_y, color='blue')\n",
    "pyplot.xlabel('Episodes (5 minutes)')\n",
    "pyplot.ylabel('Mean Episodic Reward')\n",
    "pyplot.title('MatMul/Training')\n",
    "pyplot.legend(['PPO', 'RPPO', 'DRQN'], loc='lower right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we want the Utilization plot\n",
    "# CPU Utilization\n",
    "ppox = df_ppo_['step'].to_numpy()\n",
    "ppoy = df_ppo_['cpu'].to_numpy()\n",
    "ppoy = df_ppo_['cpu'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "rppox = df_rppo_['step'].to_numpy()\n",
    "rppoy = df_rppo_['cpu'].to_numpy()\n",
    "rppoy = df_rppo_['cpu'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "dqn_x = df_dqn_['step'].to_numpy()\n",
    "dqn_y = df_dqn_['cpu'].to_numpy()\n",
    "dqn_y = df_dqn_['cpu'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "\n",
    "pyplot.plot(ppox, ppoy, color='red')\n",
    "pyplot.plot(rppox[:7705], rppoy[:7705], color='green')\n",
    "pyplot.plot(dqn_x[:7170], dqn_y[:7170], color='blue')\n",
    "pyplot.xlabel('Sampling Window (30s)')\n",
    "pyplot.ylabel('Average CPU Utilisation (x 100)')\n",
    "pyplot.title('MatMul/Training')\n",
    "pyplot.legend(['PPO', 'RPPO', 'DRQN'], loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "# Memory Utilization\n",
    "ppox = df_ppo_['step'].to_numpy()\n",
    "ppoy = df_ppo_['mem'].to_numpy()\n",
    "ppoy = df_ppo_['mem'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "rppox = df_rppo_['step'].to_numpy()\n",
    "rppoy = df_rppo_['mem'].to_numpy()\n",
    "rppoy = df_rppo_['mem'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "dqn_x = df_dqn_['step'].to_numpy()\n",
    "dqn_y = df_dqn_['mem'].to_numpy()\n",
    "dqn_y = df_dqn_['mem'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "pyplot.plot(ppox, ppoy, color='red')\n",
    "pyplot.plot(rppox[:7705], rppoy[:7705], color='green')\n",
    "pyplot.plot(dqn_x[:7170], dqn_y[:7170], color='blue')\n",
    "pyplot.xlabel('Sampling Window (30s)')\n",
    "pyplot.ylabel('Average Memory Utilisation (x 100)')\n",
    "pyplot.title('MatMul/Training')\n",
    "pyplot.legend(['PPO', 'RPPO', 'DRQN'], loc='upper right')\n",
    "pyplot.show()\n",
    "\n",
    "# Average Execution time\n",
    "ppox = df_ppo_['step'].to_numpy()\n",
    "ppoy = df_ppo_['avg_execution_time'].to_numpy()\n",
    "ppoy = df_ppo_['avg_execution_time'].rolling(window=200, min_periods=1).mean().to_numpy()\n",
    "rppox = df_rppo_['step'].to_numpy()\n",
    "rppoy = df_rppo_['avg_execution_time'].to_numpy()\n",
    "rppoy = df_rppo_['avg_execution_time'].rolling(window=200, min_periods=1).mean().to_numpy()\n",
    "dqn_x = df_dqn_['step'].to_numpy()\n",
    "dqn_y = df_dqn_['avg_execution_time'].to_numpy()\n",
    "dqn_y = df_dqn_['avg_execution_time'].rolling(window=200, min_periods=1).mean().to_numpy()\n",
    "pyplot.plot(ppox, ppoy, color='red')\n",
    "pyplot.plot(rppox[:7705], rppoy[:7705], color='green')\n",
    "pyplot.plot(dqn_x[:7170], dqn_y[:7170], color='blue')\n",
    "pyplot.xlabel('Sampling Window (30s)')\n",
    "pyplot.ylabel('Average Execution Time (s)')\n",
    "pyplot.title('MatMul/Training')\n",
    "pyplot.legend(['PPO', 'RPPO', 'DRQN'], loc='lower right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughput\n",
    "ppox = df_ppo_['step'].to_numpy()\n",
    "ppoy = df_ppo_['throughput'].to_numpy()\n",
    "ppoy = df_ppo_['throughput'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "rppox = df_rppo_['step'].to_numpy()\n",
    "rppoy = df_rppo_['throughput'].to_numpy()\n",
    "rppoy = df_rppo_['throughput'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "dqn_x = df_dqn_['step'].to_numpy()\n",
    "dqn_y = df_dqn_['throughput'].to_numpy()\n",
    "dqn_y = df_dqn_['throughput'].rolling(window=500, min_periods=10).mean().to_numpy()\n",
    "pyplot.plot(ppox, ppoy, color='red')\n",
    "pyplot.plot(rppox[:7705], rppoy[:7705], color='green')\n",
    "pyplot.plot(dqn_x[:7170], dqn_y[:7170], color='blue')\n",
    "pyplot.xlabel('Sampling Window (30s)')\n",
    "pyplot.ylabel('Throughput % (Successful/Total Requests)')\n",
    "pyplot.title('MatMul/Training')\n",
    "pyplot.legend(['PPO', 'RPPO', 'DRQN'], loc='lower right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots Execution time vs Throughput\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data\n",
    "throughput = [i for i in ppoy if i <= 100]\n",
    "response_time = df_ppo_['avg_execution_time'][:len(throughput)]\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(throughput, response_time)\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# data\n",
    "throughput = rppoy\n",
    "response_time = df_rppo_['avg_execution_time']\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(throughput, response_time)\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# data\n",
    "throughput = dqn_y[:7170]\n",
    "response_time = df_dqn_['avg_execution_time'][:7170]\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(throughput, response_time)\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-PPO, PPO, DRQN Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation data ------- environment scalars\n",
    "log_dir = './${PPO_EVAL_DIR}/scalars'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_ppo_ = reader.tensors\n",
    "\n",
    "\n",
    "log_dir = './${RPPO_EVAL_DIR}/scalars'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_rppo_ = reader.tensors\n",
    "\n",
    "log_dir = './${DQN_EVAL_DIR}'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_dqn_ = reader.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ppox = df_ppo_['step'].to_numpy()\n",
    "ppoy = df_ppo_['throughput'].to_numpy()\n",
    "# ppoy = df_ppo_['throughput'].rolling(window=100, min_periods=1).mean()\n",
    "rppox = df_rppo_['step'].to_numpy()\n",
    "rppoy = df_rppo_['throughput'].to_numpy()\n",
    "# rppoy = df_rppo_['throughput'].rolling(window=100, min_periods=1).mean()\n",
    "dqnx = df_dqn_['step'].to_numpy()\n",
    "dqny = df_dqn_['throughput'].to_numpy()\n",
    "# rppoy = df_rppo_['throughput'].rolling(window=100, min_periods=1).mean()\n",
    "\n",
    "\n",
    "# PPO Scatter Plot\n",
    "plt.scatter(df_ppo_['throughput'].to_numpy(), df_ppo_['avg_execution_time'].to_numpy())\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Rppo data\n",
    "throughput = rppoy\n",
    "response_time = df_rppo_['avg_execution_time']\n",
    "# Scatter Plot\n",
    "plt.scatter(df_rppo_['throughput'].to_numpy(), df_rppo_['avg_execution_time'].to_numpy())\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# DQRN data\n",
    "throughput = dqny\n",
    "response_time = df_dqn_['avg_execution_time'].to_numpy()\n",
    "# print(len(throughput), len(response_time))\n",
    "# Scatter Plot\n",
    "plt.scatter(df_dqn_['throughput'].to_numpy()[:200], df_dqn_['avg_execution_time'].to_numpy()[:200])\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Results comparison\n",
    "ppo_not = [i for i in df_ppo_['throughput'].to_numpy()[:200] if i < 100 and i != 0]\n",
    "rppo_not = [i for i in df_rppo_['throughput'] if i < 100 and i != 0]\n",
    "dqn_not = [i for i in df_dqn_['throughput'].to_numpy()[:200] if i < 100 and i != 0]\n",
    "print(len(ppo_not), len(df_ppo_['throughput'].to_numpy()[:200]), len(rppo_not), len(df_rppo_['throughput']))\n",
    "print(f'rppo better results tha ppo by {(len(rppo_not)/len(ppo_not))*100}')\n",
    "print(f'rppo better results tha dqn by {(len(rppo_not)/len(dqn_not))*100}')\n",
    "\n",
    "# Replicas comparison\n",
    "ppox = df_ppo_['step'].to_numpy()\n",
    "ppoy = df_ppo_['replicas'].to_numpy()\n",
    "# ppoy = df_ppo_['throughput'].rolling(window=100, min_periods=1).mean()\n",
    "rppox = df_rppo_['step'].to_numpy()\n",
    "rppoy = df_rppo_['replicas'].to_numpy()\n",
    "# rppoy = df_rppo_['throughput'].rolling(window=100, min_periods=1).mean()\n",
    "dqnx = df_dqn_['step'].to_numpy()\n",
    "dqny = df_dqn_['replicas'].to_numpy()\n",
    "# rppoy = df_rppo_['throughput'].rolling(window=100, min_periods=1).mean()\n",
    "\n",
    "pyplot.plot([i for i in range(len(ppoy))][:200], ppoy[:200], color='red')\n",
    "pyplot.plot([i for i in range(len(rppoy))][:200], rppoy[:200], color='green')\n",
    "pyplot.plot([i for i in range(len(dqny))][:200], dqny[:200], color='blue')\n",
    "pyplot.xlabel('Sampling Window (30s)')\n",
    "pyplot.ylabel('Replicas (# of Functions)')\n",
    "pyplot.title('MatMul/Evaluation')\n",
    "pyplot.legend(['PPO', 'RPPO', 'DRQN'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot replica comparison\n",
    "_data = {'PPO': [min(ppoy[:200]),max(ppoy[:200]),mean(ppoy[:200]), df_ppo_['avg_execution_time'][:200].mean()],\n",
    "        'RPPO': [min(rppoy[:200]),max(rppoy[:200]),mean(rppoy[:200]), df_rppo_['avg_execution_time'][:200].mean()],\n",
    "        'DRQN': [min(dqny[:200]),max(dqny[:200]),mean(dqny[:200]), df_dqn_['avg_execution_time'][:200].mean()]}\n",
    "_df = pd.DataFrame(_data,columns=['PPO', 'RPPO', 'DRQN'], index = ['Min. Replicas','Max. Replicas','Mean Replicas', 'Execution Time(s) '])\n",
    "\n",
    "# Multiple bar chart\n",
    "_df.plot.bar()\n",
    "\n",
    "# Display the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot throughput sample comparison\n",
    "X = ['Total Samples','100% Throughput','Non-Zero Throughput', 'Mean Throughput %']\n",
    "_data = {'PPO': [200,115,61, 67],\n",
    "        'RPPO': [200,173,11, 85],\n",
    "        'DRQN': [200, 146, 50, 67]}\n",
    "_df = pd.DataFrame(_data,columns=['PPO', 'RPPO', 'DRQN'], index = ['Total Samples','100% Throughput','Non-Zero Throughput', 'Mean Throughput %'])\n",
    "\n",
    "# Multiple bar chart\n",
    "_df.plot.bar()\n",
    "\n",
    "# Display the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPA and RPS Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection of HPA and RPS data in a similar fashion\n",
    "# training data ------- environment scalars\n",
    "log_dir = './${HPA_LOG_DIR}'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_hpa = reader.tensors\n",
    "\n",
    "\n",
    "log_dir = './${RPS_LOG_DIR}'\n",
    "reader = SummaryReader(log_dir, pivot=True)\n",
    "# print(reader.get_tags())\n",
    "df_rps = reader.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpax = df_hpa['step'].to_numpy()\n",
    "hpay = df_hpa['throughput'].to_numpy()\n",
    "hpay = df_hpa['throughput'].rolling(window=10, min_periods=10).mean().to_numpy()\n",
    "rpsx = df_rps['step'].to_numpy()\n",
    "rpsy = df_rps['throughput'].to_numpy()\n",
    "rpsy = df_rps['throughput'].rolling(window=100, min_periods=10).mean().to_numpy()\n",
    "pyplot.plot(hpax, hpay, color='red')\n",
    "pyplot.plot(rpsx, rpsy, color='green')\n",
    "pyplot.xlabel('Sampling Window (30s)')\n",
    "pyplot.ylabel('Throughput % (Successful/Total Requests)')\n",
    "pyplot.title('MatMul/HPA_RPS')\n",
    "pyplot.legend(['HPA', 'RPS'], loc='lower right')\n",
    "pyplot.show()\n",
    "\n",
    "# data\n",
    "throughput = [i for i in hpay if i <= 100]\n",
    "response_time = df_ppo_['avg_execution_time'].to_numpy()[:len(throughput)]\n",
    "\n",
    "\n",
    "hpa_not = [i for i in df_hpa['throughput'].to_numpy()[:200] if i < 100 and i != 0]\n",
    "rps_not = [i for i in df_rps['throughput'] if i < 100 and i != 0]\n",
    "\n",
    "print(len(hpa_not), len(df_hpa['throughput'].to_numpy()[:200]), len(rps_not), len(df_rps['throughput']))\n",
    "print(f'better results by {(len(rps_not)/len(hpa_not))*100}')\n",
    "print(len([i for i in df_hpa['throughput'][:200] if i == 100]))\n",
    "print(len([i for i in df_rps['throughput'][:200] if i == 100]))\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(df_hpa['throughput'], df_hpa['avg_execution_time'])\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(df_rps['throughput'], df_rps['avg_execution_time'])\n",
    "plt.xlabel('Throughput')\n",
    "plt.ylabel('Execution Time')\n",
    "plt.title('Throughput vs. Execution Time (Scatter Plot)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "hpax = df_hpa['step'].to_numpy()\n",
    "hpay = df_hpa['replicas'].to_numpy()\n",
    "# hpay = df_hpa['throughput'].rolling(window=10, min_periods=1).mean()\n",
    "rpsx = df_rps['step'].to_numpy()\n",
    "rpsy = df_rps['replicas'].to_numpy()\n",
    "# rpsy = df_rps['throughput'].rolling(window=10, min_periods=1).mean()\n",
    "pyplot.plot(hpax, hpay, color='red')\n",
    "pyplot.plot(rpsx, rpsy, color='green')\n",
    "pyplot.xlabel('Sampling Window (30s)')\n",
    "pyplot.ylabel('Replicas')\n",
    "pyplot.title('MatMul/HPA_RPS')\n",
    "pyplot.legend(['HPA', 'RPS'], loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results comparison between LSTM-PPO, PPO, DRQN, HPA and RPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_not = [i for i in df_ppo_['throughput'].to_numpy()[:200] if i < 100 and i != 0]\n",
    "rppo_not = [i for i in df_rppo_['throughput'].to_numpy()[:200] if i < 100 and i != 0]\n",
    "dqn_not = [i for i in df_dqn_['throughput'].to_numpy()[:200] if i < 100 and i != 0]\n",
    "\n",
    "print(len(ppo_not), len(df_ppo_['throughput'].to_numpy()[:200]), len(rppo_not), len(df_rppo_['throughput'].to_numpy()[:200]), len(dqn_not), len(df_dqn_['throughput'].to_numpy()[:200]))\n",
    "print(f'rppo better results than ppo by {(len(rppo_not)/len(ppo_not))*100}')\n",
    "print(f'rppo better results than dqn by {(len(rppo_not)/len(dqn_not))*100}')\n",
    "print(len([i for i in df_ppo_['throughput'].to_numpy()[:200] if i == 100]))\n",
    "print(len([i for i in df_rppo_['throughput'].to_numpy()[:200] if i == 100]))\n",
    "print(len([i for i in df_dqn_['throughput'].to_numpy()[:200] if i == 100]))\n",
    "\n",
    "\n",
    "print(mean(ppo_not))\n",
    "print(mean(rppo_not))\n",
    "print(mean(dqn_not))\n",
    "\n",
    "print(df_ppo_['avg_execution_time'].to_numpy()[:200].mean())\n",
    "print(df_rppo_['avg_execution_time'].to_numpy()[:200].mean())\n",
    "print(df_dqn_['avg_execution_time'].to_numpy()[:200].mean())\n",
    "print(mean(ppoy[:200]))\n",
    "print(mean(rppoy[:200]))\n",
    "print(mean(dqny[:200]))\n",
    "print(min(ppoy[:200]))\n",
    "print(min(ppoy[:200]))\n",
    "print(min(dqny[:200]))\n",
    "\n",
    "d = df_ppo_['replicas'].to_numpy()[:200] - df_rppo_['replicas'].to_numpy()[:200]\n",
    "print(d.mean())\n",
    "\n",
    "d = df_dqn_['replicas'].to_numpy()[:200] - df_rppo_['replicas'].to_numpy()[:200]\n",
    "print(d.mean())\n",
    "\n",
    "ppo_not = [i for i in df_hpa['throughput'].to_numpy()[:200] if i < 100 and i != 0]\n",
    "rppo_not = [i for i in df_rps['throughput'] if i < 100 and i != 0]\n",
    "\n",
    "print(len(ppo_not), len(df_hpa['throughput'].to_numpy()[:200]), len(rppo_not), len(df_rps['throughput']))\n",
    "print(f'better results by {(len(rppo_not)/len(ppo_not))*100}')\n",
    "print(len([i for i in df_hpa['throughput'].to_numpy()[:200] if i == 100]))\n",
    "print(len([i for i in df_rps['throughput'].to_numpy()[:200] if i == 100]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
